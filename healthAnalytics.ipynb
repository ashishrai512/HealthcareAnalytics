{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import *\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>patientid</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>3</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
       "0        1              8                  c                   3   \n",
       "1        2              2                  c                   5   \n",
       "2        3             10                  e                   1   \n",
       "3        4             26                  b                   2   \n",
       "4        5             26                  b                   2   \n",
       "\n",
       "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
       "0                    Z                                  3  radiotherapy   \n",
       "1                    Z                                  2  radiotherapy   \n",
       "2                    X                                  2    anesthesia   \n",
       "3                    Y                                  2  radiotherapy   \n",
       "4                    Y                                  2  radiotherapy   \n",
       "\n",
       "  Ward_Type Ward_Facility_Code  Bed Grade  patientid  City_Code_Patient  \\\n",
       "0         R                  F        2.0      31397                7.0   \n",
       "1         S                  F        2.0      31397                7.0   \n",
       "2         S                  E        2.0      31397                7.0   \n",
       "3         R                  D        2.0      31397                7.0   \n",
       "4         S                  D        2.0      31397                7.0   \n",
       "\n",
       "  Type of Admission Severity of Illness  Visitors with Patient    Age  \\\n",
       "0         Emergency             Extreme                      2  51-60   \n",
       "1            Trauma             Extreme                      2  51-60   \n",
       "2            Trauma             Extreme                      2  51-60   \n",
       "3            Trauma             Extreme                      2  51-60   \n",
       "4            Trauma             Extreme                      2  51-60   \n",
       "\n",
       "   Admission_Deposit  Stay  \n",
       "0             4911.0     0  \n",
       "1             5954.0     4  \n",
       "2             4745.0     3  \n",
       "3             7272.0     4  \n",
       "4             5558.0     4  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv('Untitled Folder/train.csv')\n",
    "test=pd.read_csv('Untitled Folder/test.csv')\n",
    "\n",
    "\n",
    "dict_stay={'0-10':0,'11-20':1, '21-30':2, '31-40':3, '41-50':4, '51-60':5, '61-70':6, '71-80':7,\n",
    "        '81-90':8, '91-100':9, 'More than 100 Days':10}\n",
    "\n",
    "train['Stay'].replace(dict_stay,inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Age</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>TB &amp; Chest disease</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>41-50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>TB &amp; Chest disease</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Minor</td>\n",
       "      <td>51-60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>TB &amp; Chest disease</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Minor</td>\n",
       "      <td>71-80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>TB &amp; Chest disease</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>21-30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>TB &amp; Chest disease</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>71-80</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hospital_type_code          Department Ward_Facility_Code  Bed Grade  \\\n",
       "0                  a  TB & Chest disease                  B        1.0   \n",
       "1                  a  TB & Chest disease                  B        1.0   \n",
       "2                  a  TB & Chest disease                  B        1.0   \n",
       "3                  a  TB & Chest disease                  B        1.0   \n",
       "4                  a  TB & Chest disease                  B        1.0   \n",
       "\n",
       "  Type of Admission Severity of Illness    Age     s0     s1     s2     s3  \\\n",
       "0         Emergency             Extreme  41-50    0.0    0.0  100.0    0.0   \n",
       "1         Emergency               Minor  51-60    0.0    0.0    0.0  100.0   \n",
       "2         Emergency               Minor  71-80    0.0  100.0    0.0    0.0   \n",
       "3         Emergency            Moderate  21-30    0.0    0.0  100.0    0.0   \n",
       "4         Emergency            Moderate  71-80  100.0    0.0    0.0    0.0   \n",
       "\n",
       "    s4   s5   s6   s7   s8   s9  s10  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg1=train.groupby(['Hospital_type_code','Department','Ward_Facility_Code','Bed Grade','Type of Admission','Severity of Illness','Age','Stay']).size().unstack().reset_index()\n",
    "agg1.columns=['Hospital_type_code', 'Department','Ward_Facility_Code' ,'Bed Grade','Type of Admission', 'Severity of Illness','Age',\n",
    "              's0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10']\n",
    "\n",
    "s_cols=['s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10']\n",
    "agg1['sum_']=agg1[s_cols].sum(axis=1)\n",
    "for col in s_cols:\n",
    "    agg1[col]=round(100*agg1[col]/agg1['sum_'],2)\n",
    "agg1.drop(['sum_'],axis=1,inplace=True)\n",
    "agg1.fillna(0,inplace=True)\n",
    "agg1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.merge(train,agg1,on=['Hospital_type_code','Department','Ward_Facility_Code','Bed Grade','Type of Admission','Severity of Illness','Age'],how='left')\n",
    "test=pd.merge(test,agg1,on=['Hospital_type_code','Department','Ward_Facility_Code','Bed Grade','Type of Admission','Severity of Illness','Age'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations={\\\n",
    "               'case_id':'count',\n",
    "               'Hospital_code':'nunique',\n",
    "               'Hospital_type_code':'nunique',\n",
    "               'City_Code_Hospital':'nunique',\n",
    "               'Hospital_region_code':'nunique',\n",
    "               'Department':'nunique',\n",
    "               'Type of Admission':'nunique',\n",
    "               'Admission_Deposit':'mean',\n",
    "             }\n",
    "\n",
    "patient_train=train.groupby(['patientid']).agg(aggregations)\n",
    "patient_test=test.groupby(['patientid']).agg(aggregations)\n",
    "                                \n",
    "\n",
    "cols=['total_visits','uniqueHos','uniqueHosType','uniqueHosCity','uniqueHosRegion','uniqueDepartment','uniqueAdm','avgDeposit']\n",
    "patient_train.columns=cols\n",
    "patient_test.columns=cols\n",
    "\n",
    "train=pd.merge(train,patient_train,on='patientid',how='left')\n",
    "test=pd.merge(test,patient_test,on='patientid',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train.drop(['Stay'],axis=1)\n",
    "\n",
    "train_X['type']='train'\n",
    "test['type']='test'\n",
    "data=pd.concat([train_X,test])\n",
    "\n",
    "#fill na using group by\n",
    "data['Bed Grade']=data.groupby(['Hospital_code'])['Bed Grade'].\\\n",
    "transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "data['City_Code_Patient']=data.groupby(['Hospital_region_code'])['City_Code_Patient'].\\\n",
    "transform(lambda x: x.fillna(x.mode()[0] if not x.mode().empty else np.nan))\n",
    "\n",
    "cat_col=['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
    "       'Hospital_region_code','Department', 'Ward_Type', 'Ward_Facility_Code',\n",
    "       'City_Code_Patient', 'Type of Admission',\n",
    "       'Severity of Illness','Age']\n",
    "\n",
    "float_col=['Available Extra Rooms in Hospital','Visitors with Patient','Admission_Deposit',\n",
    "          'total_visits','uniqueHos','uniqueHosType','uniqueHosCity','uniqueHosRegion','uniqueDepartment','uniqueAdm','avgDeposit','Bed Grade']\n",
    "\n",
    "for col in cat_col:\n",
    "    data[col]=le.fit_transform(data[col])\n",
    "\n",
    "for col in float_col:\n",
    "    data[col]=data[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregations={\\\n",
    "               'case_id':'count',\n",
    "               'patientid':'nunique' ,               \n",
    "               'Department':'nunique',\n",
    "               'Type of Admission':'nunique',\n",
    "               'Admission_Deposit':'mean',\n",
    "            }\n",
    "\n",
    "hospital_data=data.groupby(['Hospital_code']).agg(aggregations)\n",
    "\n",
    "cols=['h_cases','h_patient','h_dep','h_typeadm','h_avgdeposit']\n",
    "hospital_data.columns=cols\n",
    "\n",
    "data=pd.merge(data,hospital_data,on='Hospital_code',how='left')\n",
    "\n",
    "data['hosp_deposit']=data.groupby(['Hospital_code','Department','Type of Admission','Severity of Illness'])['Admission_Deposit'].transform('mean')\n",
    "data['per_dep_above_hosp']=100*(data['Admission_Deposit']-data['hosp_deposit'])/data['hosp_deposit']\n",
    "data['per_dep_above_patient']=100*(data['Admission_Deposit']-data['avgDeposit'])/data['avgDeposit']\n",
    "data.drop(['hosp_deposit'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=data[data['type']=='train']\n",
    "test_=data[data['type']=='test']\n",
    "train_X.drop(['type'],axis=1,inplace=True)\n",
    "test_.drop(['type'],axis=1,inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "X = train_X.drop(['case_id','patientid','City_Code_Hospital'],axis=1)\n",
    "y = train['Stay']\n",
    "test_=test_[X.columns]\n",
    "\n",
    "\n",
    "cat_col=['Hospital_code','Hospital_type_code','Ward_Facility_Code',\n",
    "       'Hospital_region_code','Department', 'Ward_Type',\n",
    "       'City_Code_Patient', 'Type of Admission',\n",
    "       'Severity of Illness','Age']\n",
    "\n",
    "cat_cols=[X.columns.get_loc(c) for c in cat_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>uniqueHos</th>\n",
       "      <th>uniqueHosType</th>\n",
       "      <th>uniqueHosCity</th>\n",
       "      <th>uniqueHosRegion</th>\n",
       "      <th>uniqueDepartment</th>\n",
       "      <th>uniqueAdm</th>\n",
       "      <th>avgDeposit</th>\n",
       "      <th>h_cases</th>\n",
       "      <th>h_patient</th>\n",
       "      <th>h_dep</th>\n",
       "      <th>h_typeadm</th>\n",
       "      <th>h_avgdeposit</th>\n",
       "      <th>per_dep_above_hosp</th>\n",
       "      <th>per_dep_above_patient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>5284</td>\n",
       "      <td>5114</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4920.411809</td>\n",
       "      <td>6.304454</td>\n",
       "      <td>-17.476054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>46.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>7277</td>\n",
       "      <td>6134</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4998.556685</td>\n",
       "      <td>20.087493</td>\n",
       "      <td>0.050412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>13538</td>\n",
       "      <td>12886</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4556.475772</td>\n",
       "      <td>-4.804895</td>\n",
       "      <td>-20.265502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.05</td>\n",
       "      <td>23.68</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>47523</td>\n",
       "      <td>37279</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4895.473644</td>\n",
       "      <td>48.723490</td>\n",
       "      <td>22.197950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.05</td>\n",
       "      <td>23.68</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>47523</td>\n",
       "      <td>37279</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4895.473644</td>\n",
       "      <td>13.669576</td>\n",
       "      <td>-6.603932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hospital_code  Hospital_type_code  Hospital_region_code  \\\n",
       "0              7                   2                     2   \n",
       "1              1                   2                     2   \n",
       "2              9                   4                     0   \n",
       "3             25                   1                     1   \n",
       "4             25                   1                     1   \n",
       "\n",
       "   Available Extra Rooms in Hospital  Department  Ward_Type  \\\n",
       "0                                3.0           3          2   \n",
       "1                                2.0           3          3   \n",
       "2                                2.0           1          3   \n",
       "3                                2.0           3          2   \n",
       "4                                2.0           3          3   \n",
       "\n",
       "   Ward_Facility_Code  Bed Grade  City_Code_Patient  Type of Admission  \\\n",
       "0                   5        2.0                  6                  0   \n",
       "1                   5        2.0                  6                  1   \n",
       "2                   4        2.0                  6                  1   \n",
       "3                   3        2.0                  6                  1   \n",
       "4                   3        2.0                  6                  1   \n",
       "\n",
       "   Severity of Illness  Visitors with Patient  Age  Admission_Deposit    s0  \\\n",
       "0                    0                    2.0    5             4911.0  20.0   \n",
       "1                    0                    2.0    5             5954.0   0.0   \n",
       "2                    0                    2.0    5             4745.0   8.0   \n",
       "3                    0                    2.0    5             7272.0   0.0   \n",
       "4                    0                    2.0    5             5558.0   0.0   \n",
       "\n",
       "      s1     s2     s3     s4     s5    s6    s7    s8    s9   s10  \\\n",
       "0   0.00  60.00  20.00   0.00   0.00  0.00   0.0   0.0  0.00  0.00   \n",
       "1   0.00  13.33  46.67   6.67  13.33  0.00  20.0   0.0  0.00  0.00   \n",
       "2  16.00  32.00  12.00   4.00  16.00  0.00   0.0  12.0  0.00  0.00   \n",
       "3  21.05  23.68  21.05  13.16  13.16  2.63   0.0   0.0  2.63  2.63   \n",
       "4  21.05  23.68  21.05  13.16  13.16  2.63   0.0   0.0  2.63  2.63   \n",
       "\n",
       "   total_visits  uniqueHos  uniqueHosType  uniqueHosCity  uniqueHosRegion  \\\n",
       "0          14.0       10.0            7.0            7.0              3.0   \n",
       "1          14.0       10.0            7.0            7.0              3.0   \n",
       "2          14.0       10.0            7.0            7.0              3.0   \n",
       "3          14.0       10.0            7.0            7.0              3.0   \n",
       "4          14.0       10.0            7.0            7.0              3.0   \n",
       "\n",
       "   uniqueDepartment  uniqueAdm  avgDeposit  h_cases  h_patient  h_dep  \\\n",
       "0               3.0        3.0      5951.0     5284       5114      5   \n",
       "1               3.0        3.0      5951.0     7277       6134      5   \n",
       "2               3.0        3.0      5951.0    13538      12886      5   \n",
       "3               3.0        3.0      5951.0    47523      37279      5   \n",
       "4               3.0        3.0      5951.0    47523      37279      5   \n",
       "\n",
       "   h_typeadm  h_avgdeposit  per_dep_above_hosp  per_dep_above_patient  \n",
       "0          3   4920.411809            6.304454             -17.476054  \n",
       "1          3   4998.556685           20.087493               0.050412  \n",
       "2          3   4556.475772           -4.804895             -20.265502  \n",
       "3          3   4895.473644           48.723490              22.197950  \n",
       "4          3   4895.473644           13.669576              -6.603932  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lgb = lgb.LGBMClassifier(boosting_type='gbdt', \n",
    "                      objective='multiclass',\n",
    "                      num_class=11,\n",
    "                      num_iteration=2000, \n",
    "                      \n",
    "                      max_depth=7,\n",
    "                      min_data_in_leaf=5,\n",
    "                     \n",
    "                      learning_rate=0.1,\n",
    "                      categorical_feature = cat_cols,\n",
    "                      random_state=101\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43,0.43,0.43,0.43,0.43,0.43,0.43,"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-b94037d7999a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mpred_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mpred_test_lgb\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mfeat_imp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \"\"\"\n\u001b[1;32m    799\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[0;32m--> 800\u001b[0;31m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    801\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[1;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m--> 607\u001b[0;31m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[1;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__pred_for_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_parameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_num_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m                 preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))\n\u001b[0m\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn_preds\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mout_num_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Wrong length for predict results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_temp=X.drop(['s0','s1','s2','s3','s4','s5','s6','s7','s8','s9','s10'],axis=1)\n",
    "test_2=test_[X_temp.columns]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=101)\n",
    "cv_score = []\n",
    "pred_test_lgb =np.zeros((len(test_),11))\n",
    "pred_train =np.zeros((len(X_temp),11))\n",
    "\n",
    "feat_imp=np.zeros((len(X_temp.columns),1))\n",
    "\n",
    "for train_index,test_index in skf.split(X_temp,y):\n",
    "    x_train,x_val = X_temp.iloc[train_index],X_temp.iloc[test_index]\n",
    "    y_train,y_val = y.iloc[train_index],y.iloc[test_index]\n",
    "    clf = clf_lgb\n",
    "    clf.fit(x_train,y_train)\n",
    "    score = round(accuracy_score(y_val,clf.predict(x_val)),2)\n",
    "    cv_score.append(score)\n",
    "    print(score,end=\",\")\n",
    "    \n",
    "    #predictions\n",
    "    pred_train += clf.predict_proba(X_temp).reshape(-1,11)\n",
    "    pred_test_lgb += clf.predict_proba(test_2).reshape(-1,11)\n",
    "    feat_imp += clf.feature_importances_.reshape(-1,1)\n",
    "    \n",
    "pred_train=pred_train/10\n",
    "pred_test_lgb = pred_test_lgb/10\n",
    "feat_imp = feat_imp/10\n",
    "\n",
    "feature_imp = pd.DataFrame(sorted(zip(X_temp.columns,feat_imp)), columns=['Feature','Value'])\n",
    "feature_imp=feature_imp.sort_values(by='Value',ascending=False)\n",
    "\n",
    "arg_pred_test=[]\n",
    "for item in pred_test_lgb:\n",
    "    arg_pred_test.append(np.argmax(item))\n",
    "    \n",
    "arg_pred_train=[]\n",
    "for item in pred_train:\n",
    "    arg_pred_train.append(np.argmax(item))\n",
    "    \n",
    "print(np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=pd.DataFrame()\n",
    "sub['Stay']=arg_pred_test\n",
    "sub.index=test.case_id\n",
    "sub=sub[['Stay']]\n",
    "inv_map_dict_stay = {v: k for k, v in dict_stay.items()}\n",
    "sub['Stay'].replace(inv_map_dict_stay,inplace=True)\n",
    "sub.to_csv('try1.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['Stay_original']=train.Stay\n",
    "df['Stay_pred']=arg_pred_train\n",
    "inv_map_dict_stay = {v: k for k, v in dict_stay.items()}\n",
    "df['Stay_original'].replace(inv_map_dict_stay,inplace=True)\n",
    "df['Stay_pred'].replace(inv_map_dict_stay,inplace=True)\n",
    "\n",
    "\n",
    "pd.crosstab(df.Stay_original,df.Stay_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>patientid</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>uniqueHos</th>\n",
       "      <th>uniqueHosType</th>\n",
       "      <th>uniqueHosCity</th>\n",
       "      <th>uniqueHosRegion</th>\n",
       "      <th>uniqueDepartment</th>\n",
       "      <th>uniqueAdm</th>\n",
       "      <th>avgDeposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>3</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0-10</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>46.67</td>\n",
       "      <td>6.67</td>\n",
       "      <td>13.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>31-40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.05</td>\n",
       "      <td>23.68</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31397</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.05</td>\n",
       "      <td>23.68</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5951.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id  Hospital_code Hospital_type_code  City_Code_Hospital  \\\n",
       "0        1              8                  c                   3   \n",
       "1        2              2                  c                   5   \n",
       "2        3             10                  e                   1   \n",
       "3        4             26                  b                   2   \n",
       "4        5             26                  b                   2   \n",
       "\n",
       "  Hospital_region_code  Available Extra Rooms in Hospital    Department  \\\n",
       "0                    Z                                  3  radiotherapy   \n",
       "1                    Z                                  2  radiotherapy   \n",
       "2                    X                                  2    anesthesia   \n",
       "3                    Y                                  2  radiotherapy   \n",
       "4                    Y                                  2  radiotherapy   \n",
       "\n",
       "  Ward_Type Ward_Facility_Code  Bed Grade  patientid  City_Code_Patient  \\\n",
       "0         R                  F        2.0      31397                7.0   \n",
       "1         S                  F        2.0      31397                7.0   \n",
       "2         S                  E        2.0      31397                7.0   \n",
       "3         R                  D        2.0      31397                7.0   \n",
       "4         S                  D        2.0      31397                7.0   \n",
       "\n",
       "  Type of Admission Severity of Illness  Visitors with Patient    Age  \\\n",
       "0         Emergency             Extreme                      2  51-60   \n",
       "1            Trauma             Extreme                      2  51-60   \n",
       "2            Trauma             Extreme                      2  51-60   \n",
       "3            Trauma             Extreme                      2  51-60   \n",
       "4            Trauma             Extreme                      2  51-60   \n",
       "\n",
       "   Admission_Deposit   Stay    s0     s1     s2     s3     s4     s5    s6  \\\n",
       "0             4911.0   0-10  20.0   0.00  60.00  20.00   0.00   0.00  0.00   \n",
       "1             5954.0  41-50   0.0   0.00  13.33  46.67   6.67  13.33  0.00   \n",
       "2             4745.0  31-40   8.0  16.00  32.00  12.00   4.00  16.00  0.00   \n",
       "3             7272.0  41-50   0.0  21.05  23.68  21.05  13.16  13.16  2.63   \n",
       "4             5558.0  41-50   0.0  21.05  23.68  21.05  13.16  13.16  2.63   \n",
       "\n",
       "     s7    s8    s9   s10  total_visits  uniqueHos  uniqueHosType  \\\n",
       "0   0.0   0.0  0.00  0.00            14         10              7   \n",
       "1  20.0   0.0  0.00  0.00            14         10              7   \n",
       "2   0.0  12.0  0.00  0.00            14         10              7   \n",
       "3   0.0   0.0  2.63  2.63            14         10              7   \n",
       "4   0.0   0.0  2.63  2.63            14         10              7   \n",
       "\n",
       "   uniqueHosCity  uniqueHosRegion  uniqueDepartment  uniqueAdm  avgDeposit  \n",
       "0              7                3                 3          3      5951.0  \n",
       "1              7                3                 3          3      5951.0  \n",
       "2              7                3                 3          3      5951.0  \n",
       "3              7                3                 3          3      5951.0  \n",
       "4              7                3                 3          3      5951.0  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt=train.copy()\n",
    "inv_map_dict_stay = {v: k for k, v in dict_stay.items()}\n",
    "opt['Stay'].replace(inv_map_dict_stay,inplace=True)\n",
    "opt=opt[opt['Stay'].isin(['0-10', '41-50', '31-40', '11-20', '51-60', '21-30'])]\n",
    "opt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt['hosp_deposit']=opt.groupby(['Hospital_code','Department','Type of Admission','Severity of Illness'])['Admission_Deposit'].transform('mean')\n",
    "opt['per_dep_above_hosp']=100*(opt['Admission_Deposit']-opt['hosp_deposit'])/opt['hosp_deposit']\n",
    "opt['per_dep_above_patient']=100*(opt['Admission_Deposit']-opt['avgDeposit'])/opt['avgDeposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stay</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0-10</th>\n",
       "      <td>23604.0</td>\n",
       "      <td>-5.275475</td>\n",
       "      <td>21.108693</td>\n",
       "      <td>-66.106824</td>\n",
       "      <td>-19.139805</td>\n",
       "      <td>-7.287388</td>\n",
       "      <td>6.105584</td>\n",
       "      <td>115.408898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-20</th>\n",
       "      <td>78139.0</td>\n",
       "      <td>0.631958</td>\n",
       "      <td>19.549712</td>\n",
       "      <td>-62.848709</td>\n",
       "      <td>-11.761959</td>\n",
       "      <td>-1.870673</td>\n",
       "      <td>10.011109</td>\n",
       "      <td>117.426303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21-30</th>\n",
       "      <td>87491.0</td>\n",
       "      <td>2.439019</td>\n",
       "      <td>19.792296</td>\n",
       "      <td>-64.396246</td>\n",
       "      <td>-9.980348</td>\n",
       "      <td>-0.200091</td>\n",
       "      <td>11.885047</td>\n",
       "      <td>133.088450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31-40</th>\n",
       "      <td>55159.0</td>\n",
       "      <td>-0.606393</td>\n",
       "      <td>21.382260</td>\n",
       "      <td>-62.018418</td>\n",
       "      <td>-14.473956</td>\n",
       "      <td>-3.709277</td>\n",
       "      <td>9.485166</td>\n",
       "      <td>137.093245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41-50</th>\n",
       "      <td>11743.0</td>\n",
       "      <td>-0.255735</td>\n",
       "      <td>22.449537</td>\n",
       "      <td>-61.404105</td>\n",
       "      <td>-13.739124</td>\n",
       "      <td>-1.765628</td>\n",
       "      <td>11.250754</td>\n",
       "      <td>132.505523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51-60</th>\n",
       "      <td>35018.0</td>\n",
       "      <td>-2.907056</td>\n",
       "      <td>23.032521</td>\n",
       "      <td>-62.940466</td>\n",
       "      <td>-17.754839</td>\n",
       "      <td>-7.252636</td>\n",
       "      <td>6.937525</td>\n",
       "      <td>137.625308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count      mean        std        min        25%       50%  \\\n",
       "Stay                                                                  \n",
       "0-10   23604.0 -5.275475  21.108693 -66.106824 -19.139805 -7.287388   \n",
       "11-20  78139.0  0.631958  19.549712 -62.848709 -11.761959 -1.870673   \n",
       "21-30  87491.0  2.439019  19.792296 -64.396246  -9.980348 -0.200091   \n",
       "31-40  55159.0 -0.606393  21.382260 -62.018418 -14.473956 -3.709277   \n",
       "41-50  11743.0 -0.255735  22.449537 -61.404105 -13.739124 -1.765628   \n",
       "51-60  35018.0 -2.907056  23.032521 -62.940466 -17.754839 -7.252636   \n",
       "\n",
       "             75%         max  \n",
       "Stay                          \n",
       "0-10    6.105584  115.408898  \n",
       "11-20  10.011109  117.426303  \n",
       "21-30  11.885047  133.088450  \n",
       "31-40   9.485166  137.093245  \n",
       "41-50  11.250754  132.505523  \n",
       "51-60   6.937525  137.625308  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.groupby(['Stay'])['per_dep_above_hosp'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stay\n",
       "0-10     AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "11-20    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "21-30    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "31-40    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "41-50    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "51-60    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: per_dep_above_hosp, dtype: object"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt.groupby(['Stay'])['per_dep_above_hosp'].plot(kind='hist',bins=np.arange(-50,50,1),alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>s0</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>s7</th>\n",
       "      <th>s8</th>\n",
       "      <th>s9</th>\n",
       "      <th>s10</th>\n",
       "      <th>total_visits</th>\n",
       "      <th>uniqueHos</th>\n",
       "      <th>uniqueHosType</th>\n",
       "      <th>uniqueHosCity</th>\n",
       "      <th>uniqueHosRegion</th>\n",
       "      <th>uniqueDepartment</th>\n",
       "      <th>uniqueAdm</th>\n",
       "      <th>avgDeposit</th>\n",
       "      <th>h_cases</th>\n",
       "      <th>h_patient</th>\n",
       "      <th>h_dep</th>\n",
       "      <th>h_typeadm</th>\n",
       "      <th>h_avgdeposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4911.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>5284</td>\n",
       "      <td>5114</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4920.411809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5954.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>46.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.33</td>\n",
       "      <td>13.33</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>7277</td>\n",
       "      <td>6134</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4998.556685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4745.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>13538</td>\n",
       "      <td>12886</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4556.475772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7272.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>21.05</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>23.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>47523</td>\n",
       "      <td>37279</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4895.473644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>21.05</td>\n",
       "      <td>21.05</td>\n",
       "      <td>13.16</td>\n",
       "      <td>23.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.63</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5951.0</td>\n",
       "      <td>47523</td>\n",
       "      <td>37279</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4895.473644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Admission_Deposit    s0     s1     s2     s3     s4     s5    s6    s7  \\\n",
       "0             4911.0  20.0   0.00  20.00   0.00   0.00  60.00   0.0  0.00   \n",
       "1             5954.0   0.0   6.67  46.67   0.00  13.33  13.33  20.0  0.00   \n",
       "2             4745.0   8.0   4.00  12.00  16.00  16.00  32.00   0.0  0.00   \n",
       "3             7272.0   0.0  13.16  21.05  21.05  13.16  23.68   0.0  2.63   \n",
       "4             5558.0   0.0  13.16  21.05  21.05  13.16  23.68   0.0  2.63   \n",
       "\n",
       "     s8    s9   s10  total_visits  uniqueHos  uniqueHosType  uniqueHosCity  \\\n",
       "0   0.0  0.00  0.00          14.0       10.0            7.0            7.0   \n",
       "1   0.0  0.00  0.00          14.0       10.0            7.0            7.0   \n",
       "2  12.0  0.00  0.00          14.0       10.0            7.0            7.0   \n",
       "3   0.0  2.63  2.63          14.0       10.0            7.0            7.0   \n",
       "4   0.0  2.63  2.63          14.0       10.0            7.0            7.0   \n",
       "\n",
       "   uniqueHosRegion  uniqueDepartment  uniqueAdm  avgDeposit  h_cases  \\\n",
       "0              3.0               3.0        3.0      5951.0     5284   \n",
       "1              3.0               3.0        3.0      5951.0     7277   \n",
       "2              3.0               3.0        3.0      5951.0    13538   \n",
       "3              3.0               3.0        3.0      5951.0    47523   \n",
       "4              3.0               3.0        3.0      5951.0    47523   \n",
       "\n",
       "   h_patient  h_dep  h_typeadm  h_avgdeposit  \n",
       "0       5114      5          3   4920.411809  \n",
       "1       6134      5          3   4998.556685  \n",
       "2      12886      5          3   4556.475772  \n",
       "3      37279      5          3   4895.473644  \n",
       "4      37279      5          3   4895.473644  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2=train_X.drop(['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
    "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
    "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade',\n",
    "       'patientid', 'City_Code_Patient', 'Type of Admission',\n",
    "       'Severity of Illness', 'Visitors with Patient', 'Age'],axis=1)\n",
    "test2=test_[train2.columns]\n",
    "\n",
    "\n",
    "impute_median=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "s_col=['s0', 's1', 's2', 's3', 's4', 's5', 's6', 's7','s8', 's9', 's10']\n",
    "for c in s_col:\n",
    "    train2[c]=impute_median.fit_transform(train2[[c]]).ravel()\n",
    "    test2[c]=impute_median.fit_transform(test2[[c]]).ravel()\n",
    "train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36,0.36,0.36,0.35,0.35,0.36,0.36,0.35,0.36,0.35,"
     ]
    }
   ],
   "source": [
    "#Logistic Doesnt improve\n",
    "# skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=101)\n",
    "# cv_score = []\n",
    "# pred_test_log =np.zeros((len(test_),11))\n",
    "\n",
    "# for train_index,test_index in skf.split(train2,y):\n",
    "#     x_train,x_val = train2.iloc[train_index],train2.iloc[test_index]\n",
    "#     y_train,y_val = y.iloc[train_index],y.iloc[test_index]\n",
    "#     clf = LogisticRegression(C=1)\n",
    "#     clf.fit(x_train,y_train)\n",
    "#     score = round(accuracy_score(y_val,clf.predict(x_val)),2)\n",
    "#     cv_score.append(score)\n",
    "#     print(score,end=\",\")\n",
    "    \n",
    "#     #predictions\n",
    "#     pred_test_log += clf.predict_proba(test2).reshape(-1,11)\n",
    "    \n",
    "# pred_test_log=pred_test_log/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 125.8858 - accuracy: 0.1908\n",
      "Epoch 2/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 37.5467 - accuracy: 0.1949\n",
      "Epoch 3/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 21.5674 - accuracy: 0.2004\n",
      "Epoch 4/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 15.6328 - accuracy: 0.2037\n",
      "Epoch 5/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 8.9822 - accuracy: 0.2100\n",
      "Epoch 6/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 7.0795 - accuracy: 0.2146\n",
      "Epoch 7/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 5.4388 - accuracy: 0.2225\n",
      "Epoch 8/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 4.7732 - accuracy: 0.2255\n",
      "Epoch 9/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 4.0897 - accuracy: 0.2324\n",
      "Epoch 10/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 3.6242 - accuracy: 0.2383\n",
      "Epoch 11/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 3.0391 - accuracy: 0.2515\n",
      "Epoch 12/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 3.0025 - accuracy: 0.2502\n",
      "Epoch 13/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.5042 - accuracy: 0.2662\n",
      "Epoch 14/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.5027 - accuracy: 0.2656\n",
      "Epoch 15/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.3571 - accuracy: 0.2759\n",
      "Epoch 16/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.2270 - accuracy: 0.2856\n",
      "Epoch 17/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.1022 - accuracy: 0.2940\n",
      "Epoch 18/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.1181 - accuracy: 0.2965\n",
      "Epoch 19/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.1605 - accuracy: 0.2955\n",
      "Epoch 20/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 2.0205 - accuracy: 0.3029\n",
      "Epoch 21/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.9779 - accuracy: 0.3062\n",
      "Epoch 22/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8962 - accuracy: 0.3179\n",
      "Epoch 23/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8627 - accuracy: 0.3229\n",
      "Epoch 24/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8682 - accuracy: 0.3211\n",
      "Epoch 25/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8601 - accuracy: 0.3216\n",
      "Epoch 26/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8426 - accuracy: 0.3240\n",
      "Epoch 27/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8313 - accuracy: 0.3270\n",
      "Epoch 28/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8388 - accuracy: 0.3243\n",
      "Epoch 29/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8182 - accuracy: 0.3297\n",
      "Epoch 30/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8140 - accuracy: 0.3290\n",
      "Epoch 31/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8080 - accuracy: 0.3313\n",
      "Epoch 32/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8087 - accuracy: 0.3293\n",
      "Epoch 33/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8004 - accuracy: 0.3315\n",
      "Epoch 34/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7974 - accuracy: 0.3325\n",
      "Epoch 35/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.9866 - accuracy: 0.3240\n",
      "Epoch 36/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.9320 - accuracy: 0.2689\n",
      "Epoch 37/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8835 - accuracy: 0.2818\n",
      "Epoch 38/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8756 - accuracy: 0.2840\n",
      "Epoch 39/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8640 - accuracy: 0.2906\n",
      "Epoch 40/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8640 - accuracy: 0.2883\n",
      "Epoch 41/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8614 - accuracy: 0.2933\n",
      "Epoch 42/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8551 - accuracy: 0.2957\n",
      "Epoch 43/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8514 - accuracy: 0.2996\n",
      "Epoch 44/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8625 - accuracy: 0.2945\n",
      "Epoch 45/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8715 - accuracy: 0.2750\n",
      "Epoch 46/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8607 - accuracy: 0.2853\n",
      "Epoch 47/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8654 - accuracy: 0.2875\n",
      "Epoch 48/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8550 - accuracy: 0.2917\n",
      "Epoch 49/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8540 - accuracy: 0.2882\n",
      "Epoch 50/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8601 - accuracy: 0.2776\n",
      "Epoch 51/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8532 - accuracy: 0.2770\n",
      "Epoch 52/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8521 - accuracy: 0.2806\n",
      "Epoch 53/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8571 - accuracy: 0.2821: 0s - loss: 1.8538 - accuracy: \n",
      "Epoch 54/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8656 - accuracy: 0.2783\n",
      "Epoch 55/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8583 - accuracy: 0.2850: 0s - loss: 1.8554 - \n",
      "Epoch 56/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8587 - accuracy: 0.2782\n",
      "Epoch 57/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8677 - accuracy: 0.2769\n",
      "Epoch 58/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8653 - accuracy: 0.2783\n",
      "Epoch 59/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8646 - accuracy: 0.2780\n",
      "Epoch 60/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8603 - accuracy: 0.2779\n",
      "Epoch 61/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8769 - accuracy: 0.2766\n",
      "Epoch 62/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8708 - accuracy: 0.2775\n",
      "Epoch 63/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8674 - accuracy: 0.2781\n",
      "Epoch 64/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8670 - accuracy: 0.2770\n",
      "Epoch 65/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8691 - accuracy: 0.2776\n",
      "Epoch 66/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8704 - accuracy: 0.2774\n",
      "Epoch 67/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8660 - accuracy: 0.2785\n",
      "Epoch 68/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8721 - accuracy: 0.2781\n",
      "Epoch 69/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8670 - accuracy: 0.2786\n",
      "Epoch 70/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8870 - accuracy: 0.2768\n",
      "Epoch 71/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8973 - accuracy: 0.2750\n",
      "Epoch 72/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8733 - accuracy: 0.2777\n",
      "Epoch 73/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8647 - accuracy: 0.2772\n",
      "Epoch 74/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8662 - accuracy: 0.2785\n",
      "Epoch 75/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8727 - accuracy: 0.2770\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8713 - accuracy: 0.2772\n",
      "Epoch 77/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8690 - accuracy: 0.2787\n",
      "Epoch 78/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8652 - accuracy: 0.2784\n",
      "Epoch 79/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.8652 - accuracy: 0.2793\n",
      "Epoch 80/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8701 - accuracy: 0.2779\n",
      "Epoch 81/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8686 - accuracy: 0.2778\n",
      "Epoch 82/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8674 - accuracy: 0.2785\n",
      "Epoch 83/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8759 - accuracy: 0.2782\n",
      "Epoch 84/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8643 - accuracy: 0.2788\n",
      "Epoch 85/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8626 - accuracy: 0.2782\n",
      "Epoch 86/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8635 - accuracy: 0.2781\n",
      "Epoch 87/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8565 - accuracy: 0.2799\n",
      "Epoch 88/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8569 - accuracy: 0.2792\n",
      "Epoch 89/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8586 - accuracy: 0.2787\n",
      "Epoch 90/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8595 - accuracy: 0.2788\n",
      "Epoch 91/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8538 - accuracy: 0.2794\n",
      "Epoch 92/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8595 - accuracy: 0.2794\n",
      "Epoch 93/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8530 - accuracy: 0.2801\n",
      "Epoch 94/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8549 - accuracy: 0.2802\n",
      "Epoch 95/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8551 - accuracy: 0.2786\n",
      "Epoch 96/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8467 - accuracy: 0.2804\n",
      "Epoch 97/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8485 - accuracy: 0.2796\n",
      "Epoch 98/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8447 - accuracy: 0.2801\n",
      "Epoch 99/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8458 - accuracy: 0.2789\n",
      "Epoch 100/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8446 - accuracy: 0.2796\n",
      "Epoch 101/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8496 - accuracy: 0.2793\n",
      "Epoch 102/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8477 - accuracy: 0.2791\n",
      "Epoch 103/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8435 - accuracy: 0.2813\n",
      "Epoch 104/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8418 - accuracy: 0.2813\n",
      "Epoch 105/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8441 - accuracy: 0.2819\n",
      "Epoch 106/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8425 - accuracy: 0.2827\n",
      "Epoch 107/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8650 - accuracy: 0.2782\n",
      "Epoch 108/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8464 - accuracy: 0.2811\n",
      "Epoch 109/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8453 - accuracy: 0.2829\n",
      "Epoch 110/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8445 - accuracy: 0.2829\n",
      "Epoch 111/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8457 - accuracy: 0.2840\n",
      "Epoch 112/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8417 - accuracy: 0.2821\n",
      "Epoch 113/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8406 - accuracy: 0.2862\n",
      "Epoch 114/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8453 - accuracy: 0.2840\n",
      "Epoch 115/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8481 - accuracy: 0.2840\n",
      "Epoch 116/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8462 - accuracy: 0.2849\n",
      "Epoch 117/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8396 - accuracy: 0.2863\n",
      "Epoch 118/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8457 - accuracy: 0.2862\n",
      "Epoch 119/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8434 - accuracy: 0.2857\n",
      "Epoch 120/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8448 - accuracy: 0.2862\n",
      "Epoch 121/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8437 - accuracy: 0.2866\n",
      "Epoch 122/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8462 - accuracy: 0.2850\n",
      "Epoch 123/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.8442 - accuracy: 0.2864\n",
      "Epoch 124/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8473 - accuracy: 0.2869\n",
      "Epoch 125/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8412 - accuracy: 0.2882\n",
      "Epoch 126/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8444 - accuracy: 0.2880\n",
      "Epoch 127/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8484 - accuracy: 0.2857\n",
      "Epoch 128/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8440 - accuracy: 0.2883\n",
      "Epoch 129/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8446 - accuracy: 0.2870\n",
      "Epoch 130/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8402 - accuracy: 0.2890\n",
      "Epoch 131/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8468 - accuracy: 0.2861\n",
      "Epoch 132/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8450 - accuracy: 0.2852\n",
      "Epoch 133/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8460 - accuracy: 0.2861\n",
      "Epoch 134/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8546 - accuracy: 0.2806\n",
      "Epoch 135/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8532 - accuracy: 0.2802\n",
      "Epoch 136/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8482 - accuracy: 0.2847\n",
      "Epoch 137/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.8486 - accuracy: 0.2855\n",
      "Epoch 138/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8480 - accuracy: 0.2871\n",
      "Epoch 139/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8470 - accuracy: 0.2883\n",
      "Epoch 140/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8441 - accuracy: 0.2879\n",
      "Epoch 141/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8466 - accuracy: 0.2884\n",
      "Epoch 142/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8412 - accuracy: 0.2922\n",
      "Epoch 143/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8194 - accuracy: 0.3089\n",
      "Epoch 144/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.8052 - accuracy: 0.3216\n",
      "Epoch 145/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7943 - accuracy: 0.3283\n",
      "Epoch 146/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7908 - accuracy: 0.3301\n",
      "Epoch 147/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7866 - accuracy: 0.3313\n",
      "Epoch 148/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7870 - accuracy: 0.3309\n",
      "Epoch 149/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7852 - accuracy: 0.3322\n",
      "Epoch 150/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7824 - accuracy: 0.3321\n",
      "Epoch 151/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7819 - accuracy: 0.3326\n",
      "Epoch 152/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7812 - accuracy: 0.3316\n",
      "Epoch 153/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7816 - accuracy: 0.3328\n",
      "Epoch 154/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7806 - accuracy: 0.3327\n",
      "Epoch 155/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7817 - accuracy: 0.3317\n",
      "Epoch 156/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7810 - accuracy: 0.3325\n",
      "Epoch 157/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7817 - accuracy: 0.3332\n",
      "Epoch 158/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7845 - accuracy: 0.3317\n",
      "Epoch 159/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7804 - accuracy: 0.3325\n",
      "Epoch 160/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7792 - accuracy: 0.3329\n",
      "Epoch 161/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7768 - accuracy: 0.3329\n",
      "Epoch 162/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7801 - accuracy: 0.3327\n",
      "Epoch 163/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7787 - accuracy: 0.3330\n",
      "Epoch 164/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7786 - accuracy: 0.3335\n",
      "Epoch 165/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7809 - accuracy: 0.3324\n",
      "Epoch 166/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7773 - accuracy: 0.3331\n",
      "Epoch 167/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7800 - accuracy: 0.3323\n",
      "Epoch 168/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7779 - accuracy: 0.3327\n",
      "Epoch 169/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7777 - accuracy: 0.3334\n",
      "Epoch 170/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7762 - accuracy: 0.3321\n",
      "Epoch 171/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7823 - accuracy: 0.3317\n",
      "Epoch 172/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7746 - accuracy: 0.3342\n",
      "Epoch 173/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7762 - accuracy: 0.3326\n",
      "Epoch 174/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7788 - accuracy: 0.3323\n",
      "Epoch 175/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7782 - accuracy: 0.3321\n",
      "Epoch 176/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7754 - accuracy: 0.3338\n",
      "Epoch 177/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7747 - accuracy: 0.3329\n",
      "Epoch 178/500\n",
      "286589/286589 [==============================] - 331s 1ms/step - loss: 1.7747 - accuracy: 0.3324\n",
      "Epoch 179/500\n",
      "286589/286589 [==============================] - 2s 6us/step - loss: 1.7742 - accuracy: 0.3327\n",
      "Epoch 180/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7760 - accuracy: 0.3330\n",
      "Epoch 181/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7751 - accuracy: 0.3336\n",
      "Epoch 182/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7755 - accuracy: 0.3340\n",
      "Epoch 183/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7768 - accuracy: 0.3326\n",
      "Epoch 184/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7800 - accuracy: 0.3313\n",
      "Epoch 185/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7739 - accuracy: 0.3336\n",
      "Epoch 186/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7738 - accuracy: 0.3332\n",
      "Epoch 187/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7718 - accuracy: 0.3343\n",
      "Epoch 188/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7743 - accuracy: 0.3339\n",
      "Epoch 189/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7756 - accuracy: 0.3335\n",
      "Epoch 190/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7747 - accuracy: 0.3327\n",
      "Epoch 191/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7734 - accuracy: 0.3328\n",
      "Epoch 192/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7728 - accuracy: 0.3334\n",
      "Epoch 193/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7739 - accuracy: 0.3326\n",
      "Epoch 194/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7719 - accuracy: 0.3338\n",
      "Epoch 195/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7740 - accuracy: 0.3336\n",
      "Epoch 196/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7735 - accuracy: 0.3330\n",
      "Epoch 197/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7712 - accuracy: 0.3338\n",
      "Epoch 198/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7738 - accuracy: 0.3324\n",
      "Epoch 199/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7732 - accuracy: 0.3333\n",
      "Epoch 200/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7721 - accuracy: 0.3337\n",
      "Epoch 201/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7711 - accuracy: 0.3335\n",
      "Epoch 202/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7714 - accuracy: 0.3339\n",
      "Epoch 203/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7707 - accuracy: 0.3332\n",
      "Epoch 204/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7718 - accuracy: 0.3330\n",
      "Epoch 205/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7711 - accuracy: 0.3336\n",
      "Epoch 206/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7700 - accuracy: 0.3339\n",
      "Epoch 207/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7701 - accuracy: 0.3336\n",
      "Epoch 208/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7728 - accuracy: 0.3328\n",
      "Epoch 209/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7742 - accuracy: 0.3336\n",
      "Epoch 210/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7720 - accuracy: 0.3321\n",
      "Epoch 211/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7715 - accuracy: 0.3333\n",
      "Epoch 212/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7717 - accuracy: 0.3337\n",
      "Epoch 213/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7717 - accuracy: 0.3328\n",
      "Epoch 214/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7721 - accuracy: 0.3337\n",
      "Epoch 215/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7721 - accuracy: 0.3331\n",
      "Epoch 216/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7718 - accuracy: 0.3322\n",
      "Epoch 217/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7702 - accuracy: 0.3342\n",
      "Epoch 218/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7708 - accuracy: 0.3335\n",
      "Epoch 219/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7769 - accuracy: 0.3314\n",
      "Epoch 220/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7713 - accuracy: 0.3325\n",
      "Epoch 221/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7703 - accuracy: 0.3341\n",
      "Epoch 222/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7706 - accuracy: 0.3341\n",
      "Epoch 223/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7715 - accuracy: 0.3333\n",
      "Epoch 224/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7711 - accuracy: 0.3334\n",
      "Epoch 225/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7689 - accuracy: 0.3340\n",
      "Epoch 226/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7716 - accuracy: 0.3334\n",
      "Epoch 227/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7721 - accuracy: 0.3332\n",
      "Epoch 228/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7703 - accuracy: 0.3339\n",
      "Epoch 229/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7686 - accuracy: 0.3342\n",
      "Epoch 230/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7720 - accuracy: 0.3328\n",
      "Epoch 231/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7693 - accuracy: 0.3347\n",
      "Epoch 232/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7695 - accuracy: 0.3337\n",
      "Epoch 233/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7727 - accuracy: 0.3333\n",
      "Epoch 234/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7721 - accuracy: 0.3332\n",
      "Epoch 235/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7700 - accuracy: 0.3338\n",
      "Epoch 236/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7701 - accuracy: 0.3337\n",
      "Epoch 237/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7684 - accuracy: 0.3347\n",
      "Epoch 238/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7697 - accuracy: 0.3337\n",
      "Epoch 239/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7688 - accuracy: 0.3342\n",
      "Epoch 240/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7726 - accuracy: 0.3322\n",
      "Epoch 241/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7684 - accuracy: 0.3351\n",
      "Epoch 242/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7685 - accuracy: 0.3337\n",
      "Epoch 243/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7695 - accuracy: 0.3339\n",
      "Epoch 244/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7702 - accuracy: 0.3333\n",
      "Epoch 245/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7685 - accuracy: 0.3337\n",
      "Epoch 246/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7715 - accuracy: 0.3319\n",
      "Epoch 247/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7666 - accuracy: 0.3345\n",
      "Epoch 248/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7685 - accuracy: 0.3342\n",
      "Epoch 249/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7702 - accuracy: 0.3341\n",
      "Epoch 250/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7683 - accuracy: 0.3341\n",
      "Epoch 251/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7724 - accuracy: 0.3316\n",
      "Epoch 252/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7692 - accuracy: 0.3341\n",
      "Epoch 253/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7677 - accuracy: 0.3349\n",
      "Epoch 254/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7675 - accuracy: 0.3338\n",
      "Epoch 255/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7669 - accuracy: 0.3342: 0s - loss: 1.7675 - accuracy: \n",
      "Epoch 256/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7673 - accuracy: 0.3349\n",
      "Epoch 257/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7671 - accuracy: 0.3345\n",
      "Epoch 258/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7709 - accuracy: 0.3338\n",
      "Epoch 259/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7667 - accuracy: 0.3348\n",
      "Epoch 260/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7691 - accuracy: 0.3333\n",
      "Epoch 261/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7669 - accuracy: 0.3348\n",
      "Epoch 262/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7676 - accuracy: 0.3338\n",
      "Epoch 263/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7690 - accuracy: 0.3336\n",
      "Epoch 264/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7666 - accuracy: 0.3350\n",
      "Epoch 265/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7688 - accuracy: 0.3333\n",
      "Epoch 266/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7710 - accuracy: 0.3325\n",
      "Epoch 267/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7683 - accuracy: 0.3337\n",
      "Epoch 268/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7671 - accuracy: 0.3345\n",
      "Epoch 269/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7691 - accuracy: 0.3331\n",
      "Epoch 270/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7723 - accuracy: 0.3323\n",
      "Epoch 271/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7738 - accuracy: 0.3309\n",
      "Epoch 272/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7700 - accuracy: 0.3337\n",
      "Epoch 273/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7670 - accuracy: 0.3337\n",
      "Epoch 274/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7662 - accuracy: 0.3348\n",
      "Epoch 275/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7702 - accuracy: 0.3327\n",
      "Epoch 276/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7675 - accuracy: 0.3341\n",
      "Epoch 277/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7683 - accuracy: 0.3333\n",
      "Epoch 278/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7678 - accuracy: 0.3345\n",
      "Epoch 279/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7671 - accuracy: 0.3345\n",
      "Epoch 280/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7658 - accuracy: 0.3347\n",
      "Epoch 281/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7689 - accuracy: 0.3344\n",
      "Epoch 282/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7662 - accuracy: 0.3345\n",
      "Epoch 283/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7668 - accuracy: 0.3342\n",
      "Epoch 284/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7676 - accuracy: 0.3340\n",
      "Epoch 285/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7685 - accuracy: 0.3342\n",
      "Epoch 286/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7733 - accuracy: 0.3330\n",
      "Epoch 287/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7713 - accuracy: 0.3322\n",
      "Epoch 288/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7731 - accuracy: 0.3315\n",
      "Epoch 289/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7843 - accuracy: 0.3306\n",
      "Epoch 290/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7666 - accuracy: 0.3352\n",
      "Epoch 291/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7678 - accuracy: 0.3337\n",
      "Epoch 292/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7668 - accuracy: 0.3337\n",
      "Epoch 293/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7657 - accuracy: 0.3352\n",
      "Epoch 294/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7700 - accuracy: 0.3341\n",
      "Epoch 295/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7662 - accuracy: 0.3348\n",
      "Epoch 296/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7657 - accuracy: 0.3353\n",
      "Epoch 297/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7914 - accuracy: 0.3318\n",
      "Epoch 298/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7804 - accuracy: 0.3318\n",
      "Epoch 299/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7695 - accuracy: 0.3336\n",
      "Epoch 300/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7697 - accuracy: 0.3330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7708 - accuracy: 0.3329\n",
      "Epoch 302/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7659 - accuracy: 0.3355\n",
      "Epoch 303/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7689 - accuracy: 0.3340\n",
      "Epoch 304/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7671 - accuracy: 0.3348\n",
      "Epoch 305/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7765 - accuracy: 0.3288\n",
      "Epoch 306/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7648 - accuracy: 0.3351\n",
      "Epoch 307/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7676 - accuracy: 0.3349\n",
      "Epoch 308/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7662 - accuracy: 0.3349\n",
      "Epoch 309/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7662 - accuracy: 0.3343\n",
      "Epoch 310/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7656 - accuracy: 0.3346\n",
      "Epoch 311/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7663 - accuracy: 0.3347\n",
      "Epoch 312/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7673 - accuracy: 0.3341\n",
      "Epoch 313/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7686 - accuracy: 0.3337\n",
      "Epoch 314/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7685 - accuracy: 0.3342\n",
      "Epoch 315/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7638 - accuracy: 0.3364\n",
      "Epoch 316/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7687 - accuracy: 0.3338\n",
      "Epoch 317/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7699 - accuracy: 0.3335\n",
      "Epoch 318/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7640 - accuracy: 0.3356\n",
      "Epoch 319/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7668 - accuracy: 0.3349\n",
      "Epoch 320/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7673 - accuracy: 0.3340\n",
      "Epoch 321/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7629 - accuracy: 0.3357\n",
      "Epoch 322/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.7664 - accuracy: 0.3354\n",
      "Epoch 323/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7669 - accuracy: 0.3339\n",
      "Epoch 324/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7662 - accuracy: 0.3345\n",
      "Epoch 325/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7636 - accuracy: 0.3358\n",
      "Epoch 326/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.7710 - accuracy: 0.3314\n",
      "Epoch 327/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7660 - accuracy: 0.3350\n",
      "Epoch 328/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.7629 - accuracy: 0.3357\n",
      "Epoch 329/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7659 - accuracy: 0.3338\n",
      "Epoch 330/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7629 - accuracy: 0.3363\n",
      "Epoch 331/500\n",
      "286589/286589 [==============================] - 2s 5us/step - loss: 1.7681 - accuracy: 0.3327\n",
      "Epoch 332/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7641 - accuracy: 0.3357\n",
      "Epoch 333/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7744 - accuracy: 0.3323\n",
      "Epoch 334/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7712 - accuracy: 0.3324\n",
      "Epoch 335/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7630 - accuracy: 0.3354\n",
      "Epoch 336/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7620 - accuracy: 0.3366\n",
      "Epoch 337/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7652 - accuracy: 0.3341\n",
      "Epoch 338/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7623 - accuracy: 0.3352\n",
      "Epoch 339/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7665 - accuracy: 0.3344\n",
      "Epoch 340/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7638 - accuracy: 0.3350\n",
      "Epoch 341/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7665 - accuracy: 0.3334\n",
      "Epoch 342/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7635 - accuracy: 0.3359\n",
      "Epoch 343/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7667 - accuracy: 0.3337\n",
      "Epoch 344/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7639 - accuracy: 0.3347\n",
      "Epoch 345/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7647 - accuracy: 0.3340\n",
      "Epoch 346/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7618 - accuracy: 0.3364\n",
      "Epoch 347/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7624 - accuracy: 0.3353\n",
      "Epoch 348/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7623 - accuracy: 0.3360\n",
      "Epoch 349/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7640 - accuracy: 0.3356\n",
      "Epoch 350/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7634 - accuracy: 0.3359\n",
      "Epoch 351/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7668 - accuracy: 0.3343\n",
      "Epoch 352/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7788 - accuracy: 0.3278\n",
      "Epoch 353/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7647 - accuracy: 0.3349\n",
      "Epoch 354/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7610 - accuracy: 0.3366\n",
      "Epoch 355/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7623 - accuracy: 0.3356\n",
      "Epoch 356/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7608 - accuracy: 0.3364\n",
      "Epoch 357/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7613 - accuracy: 0.3369\n",
      "Epoch 358/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7653 - accuracy: 0.3345\n",
      "Epoch 359/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7608 - accuracy: 0.3359\n",
      "Epoch 360/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7611 - accuracy: 0.3360\n",
      "Epoch 361/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7610 - accuracy: 0.3359\n",
      "Epoch 362/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7625 - accuracy: 0.3351\n",
      "Epoch 363/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7613 - accuracy: 0.3358\n",
      "Epoch 364/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7618 - accuracy: 0.3355\n",
      "Epoch 365/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7644 - accuracy: 0.3346\n",
      "Epoch 366/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7723 - accuracy: 0.3323\n",
      "Epoch 367/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7611 - accuracy: 0.3362\n",
      "Epoch 368/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7598 - accuracy: 0.3359\n",
      "Epoch 369/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7694 - accuracy: 0.3322\n",
      "Epoch 370/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7716 - accuracy: 0.3326\n",
      "Epoch 371/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7639 - accuracy: 0.3357\n",
      "Epoch 372/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7613 - accuracy: 0.3353\n",
      "Epoch 373/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7630 - accuracy: 0.3354\n",
      "Epoch 374/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7613 - accuracy: 0.3354\n",
      "Epoch 375/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7608 - accuracy: 0.3359\n",
      "Epoch 376/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7628 - accuracy: 0.3345\n",
      "Epoch 377/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7605 - accuracy: 0.3360\n",
      "Epoch 378/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7632 - accuracy: 0.3360\n",
      "Epoch 379/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7616 - accuracy: 0.3364\n",
      "Epoch 380/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7675 - accuracy: 0.3324\n",
      "Epoch 381/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7653 - accuracy: 0.3342\n",
      "Epoch 382/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7611 - accuracy: 0.3361\n",
      "Epoch 383/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7626 - accuracy: 0.3344\n",
      "Epoch 384/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7667 - accuracy: 0.3347\n",
      "Epoch 385/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7601 - accuracy: 0.3358\n",
      "Epoch 386/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7628 - accuracy: 0.3352\n",
      "Epoch 387/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7922 - accuracy: 0.3279\n",
      "Epoch 388/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7629 - accuracy: 0.3351\n",
      "Epoch 389/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7596 - accuracy: 0.3361\n",
      "Epoch 390/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7651 - accuracy: 0.3341\n",
      "Epoch 391/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7604 - accuracy: 0.3365\n",
      "Epoch 392/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7646 - accuracy: 0.3346\n",
      "Epoch 393/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7670 - accuracy: 0.3315\n",
      "Epoch 394/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7637 - accuracy: 0.3340\n",
      "Epoch 395/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7587 - accuracy: 0.3363\n",
      "Epoch 396/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7724 - accuracy: 0.3311\n",
      "Epoch 397/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7631 - accuracy: 0.3344\n",
      "Epoch 398/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7591 - accuracy: 0.3364\n",
      "Epoch 399/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7663 - accuracy: 0.3326\n",
      "Epoch 400/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7596 - accuracy: 0.3361\n",
      "Epoch 401/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7585 - accuracy: 0.3365\n",
      "Epoch 402/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7580 - accuracy: 0.3370\n",
      "Epoch 403/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7635 - accuracy: 0.3345\n",
      "Epoch 404/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7571 - accuracy: 0.3375\n",
      "Epoch 405/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7542 - accuracy: 0.3395\n",
      "Epoch 406/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7535 - accuracy: 0.3418\n",
      "Epoch 407/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7611 - accuracy: 0.3395\n",
      "Epoch 408/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7450 - accuracy: 0.3467\n",
      "Epoch 409/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7479 - accuracy: 0.3462\n",
      "Epoch 410/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7384 - accuracy: 0.3500\n",
      "Epoch 411/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7373 - accuracy: 0.3501\n",
      "Epoch 412/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7350 - accuracy: 0.3509\n",
      "Epoch 413/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7332 - accuracy: 0.3513\n",
      "Epoch 414/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7377 - accuracy: 0.3487\n",
      "Epoch 415/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7334 - accuracy: 0.3510\n",
      "Epoch 416/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7327 - accuracy: 0.3514\n",
      "Epoch 417/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7301 - accuracy: 0.3514\n",
      "Epoch 418/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7309 - accuracy: 0.3513\n",
      "Epoch 419/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7371 - accuracy: 0.3491\n",
      "Epoch 420/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7276 - accuracy: 0.3521\n",
      "Epoch 421/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7257 - accuracy: 0.3530\n",
      "Epoch 422/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7309 - accuracy: 0.3512\n",
      "Epoch 423/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7247 - accuracy: 0.3530\n",
      "Epoch 424/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7259 - accuracy: 0.3525\n",
      "Epoch 425/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7249 - accuracy: 0.3529\n",
      "Epoch 426/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7231 - accuracy: 0.3524\n",
      "Epoch 427/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7271 - accuracy: 0.3528\n",
      "Epoch 428/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7232 - accuracy: 0.3526\n",
      "Epoch 429/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7221 - accuracy: 0.3533\n",
      "Epoch 430/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7227 - accuracy: 0.3525\n",
      "Epoch 431/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7223 - accuracy: 0.3527\n",
      "Epoch 432/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7240 - accuracy: 0.3528\n",
      "Epoch 433/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7208 - accuracy: 0.3534\n",
      "Epoch 434/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7208 - accuracy: 0.3534\n",
      "Epoch 435/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7220 - accuracy: 0.3532\n",
      "Epoch 436/500\n",
      "286589/286589 [==============================] - 1s 5us/step - loss: 1.7233 - accuracy: 0.3533\n",
      "Epoch 437/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7230 - accuracy: 0.3522\n",
      "Epoch 438/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7248 - accuracy: 0.3517\n",
      "Epoch 439/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7214 - accuracy: 0.3527\n",
      "Epoch 440/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7269 - accuracy: 0.3519\n",
      "Epoch 441/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7193 - accuracy: 0.3531\n",
      "Epoch 442/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7216 - accuracy: 0.3526\n",
      "Epoch 443/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7207 - accuracy: 0.3538\n",
      "Epoch 444/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7199 - accuracy: 0.3536\n",
      "Epoch 445/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7224 - accuracy: 0.3528\n",
      "Epoch 446/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7179 - accuracy: 0.3547\n",
      "Epoch 447/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7240 - accuracy: 0.3516\n",
      "Epoch 448/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7192 - accuracy: 0.3535\n",
      "Epoch 449/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7185 - accuracy: 0.3544\n",
      "Epoch 450/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7196 - accuracy: 0.3536\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7198 - accuracy: 0.3538\n",
      "Epoch 452/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7231 - accuracy: 0.3521\n",
      "Epoch 453/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7201 - accuracy: 0.3536\n",
      "Epoch 454/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7208 - accuracy: 0.3534\n",
      "Epoch 455/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7182 - accuracy: 0.3537\n",
      "Epoch 456/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7192 - accuracy: 0.3538\n",
      "Epoch 457/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7185 - accuracy: 0.3535\n",
      "Epoch 458/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7193 - accuracy: 0.3535\n",
      "Epoch 459/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7211 - accuracy: 0.3528\n",
      "Epoch 460/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7190 - accuracy: 0.3530\n",
      "Epoch 461/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7176 - accuracy: 0.3540\n",
      "Epoch 462/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7187 - accuracy: 0.3539\n",
      "Epoch 463/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7183 - accuracy: 0.3534\n",
      "Epoch 464/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7186 - accuracy: 0.3540\n",
      "Epoch 465/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7188 - accuracy: 0.3534\n",
      "Epoch 466/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7171 - accuracy: 0.3540\n",
      "Epoch 467/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7167 - accuracy: 0.3543\n",
      "Epoch 468/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7162 - accuracy: 0.3541\n",
      "Epoch 469/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7163 - accuracy: 0.3542\n",
      "Epoch 470/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7171 - accuracy: 0.3535\n",
      "Epoch 471/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7184 - accuracy: 0.3536\n",
      "Epoch 472/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7170 - accuracy: 0.3543\n",
      "Epoch 473/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7180 - accuracy: 0.3530\n",
      "Epoch 474/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7170 - accuracy: 0.3541\n",
      "Epoch 475/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7185 - accuracy: 0.3532\n",
      "Epoch 476/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7213 - accuracy: 0.3526\n",
      "Epoch 477/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7162 - accuracy: 0.3550\n",
      "Epoch 478/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7172 - accuracy: 0.3544\n",
      "Epoch 479/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7190 - accuracy: 0.3528\n",
      "Epoch 480/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7163 - accuracy: 0.3544\n",
      "Epoch 481/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7161 - accuracy: 0.3534\n",
      "Epoch 482/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7174 - accuracy: 0.3534\n",
      "Epoch 483/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7306 - accuracy: 0.3510\n",
      "Epoch 484/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7163 - accuracy: 0.3544\n",
      "Epoch 485/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7171 - accuracy: 0.3545\n",
      "Epoch 486/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7173 - accuracy: 0.3538\n",
      "Epoch 487/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7154 - accuracy: 0.3548\n",
      "Epoch 488/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7149 - accuracy: 0.3545\n",
      "Epoch 489/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7249 - accuracy: 0.3519\n",
      "Epoch 490/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7170 - accuracy: 0.3542\n",
      "Epoch 491/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7153 - accuracy: 0.3542\n",
      "Epoch 492/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7186 - accuracy: 0.3540\n",
      "Epoch 493/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7192 - accuracy: 0.3521\n",
      "Epoch 494/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7149 - accuracy: 0.3549\n",
      "Epoch 495/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7149 - accuracy: 0.3544\n",
      "Epoch 496/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7139 - accuracy: 0.3549\n",
      "Epoch 497/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7143 - accuracy: 0.3552\n",
      "Epoch 498/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7170 - accuracy: 0.3544\n",
      "Epoch 499/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7156 - accuracy: 0.3544\n",
      "Epoch 500/500\n",
      "286589/286589 [==============================] - 1s 4us/step - loss: 1.7172 - accuracy: 0.3537\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'predict_classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c526fa613091>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mcv_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'predict_classes'"
     ]
    }
   ],
   "source": [
    "def keras_model(input_dim=len(train2.columns)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim = input_dim , activation = 'relu'))\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "#     model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dense(11, activation = 'softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy' , optimizer = 'adam' , metrics = ['accuracy'] )\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=101)\n",
    "cv_score = []\n",
    "pred_test_log =np.zeros((len(test_),11))\n",
    "dummy_y = np_utils.to_categorical(y)\n",
    "\n",
    "for train_index,test_index in skf.split(train2,y):\n",
    "    x_train,x_val = train2.iloc[train_index],train2.iloc[test_index]\n",
    "    y_train,y_val = y.iloc[train_index],y.iloc[test_index]\n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train)\n",
    "    \n",
    "    model=keras_model().fit(x_train, y_train, epochs = 500, batch_size = 1000)\n",
    "    score = round(accuracy_score(y_val,model.model.predict_classes(x_val)),2)\n",
    "    cv_score.append(score)\n",
    "    print(score,end=\",\")\n",
    "    \n",
    "    #predictions\n",
    "    pred_test_keras += model.model.predict_proba(test2).reshape(-1,11)\n",
    "    \n",
    "pred_test_keras=pred_test_keras/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=model.model.predict_classes(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-844784619163>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "round(accuracy_score(y_val,model.model.predict_classes(x_val)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_final=(pred_test_lgb+pred_test_keras)/2\n",
    "arg_pred_final=[]\n",
    "for item in pred_test_final:\n",
    "    arg_pred_final.append(np.argmax(item))\n",
    "    \n",
    "sub=pd.DataFrame()\n",
    "sub['Stay']=arg_pred_final\n",
    "sub.index=test.case_id\n",
    "sub=sub[['Stay']]\n",
    "inv_map_dict_stay = {v: k for k, v in dict_stay.items()}\n",
    "sub['Stay'].replace(inv_map_dict_stay,inplace=True)\n",
    "sub.to_csv('try1.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #grid search for best param\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42).split(X,y)\n",
    "\n",
    "# param_grid = {\n",
    "#     'objective':'multiclass',\n",
    "#     'num_class':[11],\n",
    "#     'num_iteration':[1000],\n",
    "#     'max_depth':[5,7],\n",
    "#     'num_leaves': [30, 100],\n",
    "#     'min_data_in_leaf': [5,10],\n",
    "#     'learning_rate':[0.1],\n",
    "#     }\n",
    "\n",
    "# gsearch=GridSearchCV(estimator=clf_lgb,param_grid=param_grid,n_jobs=-1,verbose=0,return_train_score=True,cv=kf)\n",
    "\n",
    "# lgb_model = gsearch.fit(X,y)\n",
    "# print(lgb_model.best_params_, lgb_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat=CatBoostClassifier(iterations=1000,  \n",
    "#                          learning_rate=0.1,\n",
    "#                          loss_function='MultiClass',\n",
    "#                          cat_features = cat_cols,\n",
    "#                         verbose=False\n",
    "#                         )\n",
    "\n",
    "# x_train,x_test,y_train,y_test=train_test_split(X,y)\n",
    "# clf=cat.fit(x_train,y_train)\n",
    "# print(accuracy_score(y_test,clf.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
